#!/bin/bash
if test "$SHELL" = "/bin/sh" && test -x /bin/bash; then
    exec /bin/bash -c "$0" "$@"
fi

####################################################################################
# cache_dirs
# A utility to attempt to keep directory entries in the linux
# buffer cache to allow disks to spin down and no need to spin-up
# simply to get a directory listing on an unRAID server.
#
# Version 1.0   Initial proof of concept using "ls -R"
# Version 1.1   Working version, using "ls -R" or "find -maxdepth"
# Version 1.2   Able to be used with or without presence of user-shares.  
#               Removed "ls -R" as it was too easy to run out of ram. (ask me how I know)
#               Added -i include_dir to explicitly state cached directories
#               Added -v option, verbose statistics when run in foreground
#               Added -q option, to easily terminate a process run in the background
#               Added logging of command line parameters to syslog
# Version 1.3   Added -w option, to wait till array comes online before starting scan
#               of /mnt/disk* share folders.
#               Changed min-seconds delay between scans to 1 instead of 0.
#               Moved test of include/exclude directories to after array is on-line
#               Added logging of mis-spelled/missing include/exclude dirs to syslog
#               Added ability to have shell wildcard expansion in include/exclude names
# Version 1.4   Fix bug with argument order passed to find when using -d option
#               Fixed command submitted to "at" to use full path. Should not need to
#              set PATH variable in "go" script.
#               Added ability to also cache scan /mnt/user with -u option
# Version 1.4.1 Fixed version comment so it is actually a comment.
# Version 1.5   Added -V to print version number.
#               Added explicit cache of root directories on disks and cache drive
#               Modified "average" scan time statistic to be weighted average with a window
#               of recent samples.
#               Added -a args option to allow entry of args to commands after dir/file name
#                 example: cache_dirs -a "-ls" -d 3
#                 This will execute "find disk/share -ls -maxdepth 3"
# Version 1.6   - Fixed bug... if -q was used, and cache_dirs not currently running, 
#               it started running in error. OOps... Added the missing "exit"
#               - Changed vfs_cache_pressure setting to be 1 instead of 0 by default.
#               - Added "-p cache_pressure" to allow experimentation with vfs_cache_pressure values
#                (If not specified, default value of 1 will be used)
#               - Made -noleaf the default behavior for the "find" command (use -a "" to disable).
#               - Added logic to force all disks "busy" by starting a process with each as their
#               current working directory.   This will prevent a user from seeing a frightening
#               Unformatted description if they attempt to stop the array.  A second "Stop" will
#               succeed (the scan is paused for 2 minutes, so it may be stopped cleanly)
#               - Added new -B option to revert to the old behaviour and not force disks busy if by 
#               chance this new feature causes problems for some users.
#               - Allow min seconds to be equal to max seconds in loop delay range.
#               - Added run-time-logging, log name = /var/log/cache_dirs.log 
# Version 1.6.1 - Fixed bug. Added missing /mnt/cache disk to scanned directories
# Version 1.6.2 - Added trap to clean up processes after kill signal when run in background
# Version 1.6.3 - Modified to deal with new un-mounting message in syslog in 4.5b7 to 
#                 allow array shutdown to occur cleanly.
# Version 1.6.4 - Modified to suspend scan during time "mover" script is running to prevent 
#                 DuplicateFile messages from occurring as file is being copied.
#               - Added -S option to NOT suspend scan during mover process.
#               - Added logic to re-invoke cache_dirs if array is stopped and then re-started
#                 by submitting command string to "at" to re-invoke in a minute. 
#               - Added entry to "usage()" function for -B
# Version 1.6.5 - Fixed what I broke in looking for "mover" pid to suspend during the "mover"
#                 to eliminate warnings in syslog about duplicate files detected while files were
#                 being copied.
# Version 1.6.6 - Fixed mover-detection to use the exact same logic as "mover" (and fixed stupid typo I had made)
# Version 1.6.7 - Added cache_pressure to "usage" statement, fixed bug where it reverted to 10 after being invoked through "at"
#                 when used with the -w option.
#
#
# Joe L.
####################################################################################
version=1.6.7
program_name=`basename $0`
program_dir=`dirname $0`
arg_count=$#

usage() {
 echo
 echo "Usage: $program_name [-m min_seconds] [-M max_seconds] [-F] [-d maxdepth] [-c command] [-a args] [-e exclude_dir] [-i include_dir] [-w]"
 echo "       $program_name -V      = print program version "
 echo "       $program_name -q"
 echo "       $program_name -l on   = turn on logging to /var/log/cache_dirs.log"
 echo "       $program_name -l off  = turn off logging to /var/log/cache_dirs.log"
 echo " -w       =   wait for array to come online before start of cache scan of directories"
 echo " -m NN    =   minimum seconds to wait between directory scans (default=1)"
 echo " -M NN    =   maximum seconds to wait between directory scans (default=10)"
 echo " -F       =   do NOT run in background, run in Foreground and print statistics as it loops and scans"
 echo " -v       =   when used with -F, verbose statistics are printed as directories are scanned"
 echo " -s       =   shorter-log - print count of directories scanned to syslog instead of their names"
 echo " -d NN    =   use \"find -maxdepth NN\" instead of \"find -maxdepth 999\" "
 echo " -c command   = use command instead of \"find\" "
 echo "              ("command" should be quoted if it has embedded spaces)"
 echo " -a args    = append args to command"
 echo " -u       =   also scan /mnt/user (scan user shares)"
 echo " -e exclude_dir  (may be repeated as many times as desired)"
 echo " -i include_dir  (may be repeated as many times as desired)"
 echo " -p NN    =   set cache_pressure to NN (by default it is set to 10)"
 echo " -B       =   do not force disks busy (to prevent unmounted disks showing as unformatted)"
 echo " -S       =   do not suspend scan during 'mover' process"
 echo " -z       = concise log (log run criteria on one line)"
 echo " -q       = terminate any background instance of cache_dirs"
}

# if we detect an attempt to stop the array without quiting this cache_dirs program we will
# suspend the scanning of directories for a duration to allow a clean Stop of the array.
# (Basically, press the "Stop" button again within this window of time as first will NOT
# stop the array since we have forced  all the disks busy. )
suspend_secs=120

background=yes
verbose=no
min_seconds=1
max_seconds=10
use_find=no
short_log=no
maxdepth=9999
command="find"
window_array_length=20
avg_elapsed_time=0
exclude_array_count=0
include_array_count=0
quit_flag="no"
force_disk_busy_flag="yes"
suspend_during_mover="yes"
wait_flag="no"
commandargs=$*
user_share_dir=""
args="-noleaf"
concise_log="no"
run_log="/var/log/cache_dirs.log"
debug_output=0

# cache_pressure of 0 will potentially run out of RAM if a large directory is scanned and not enough RAM
# esists. User processes will then be killed to free space rather than cache freed.  
# (It has happened several times on my server when I forgot to exclude my data folder. 
# It is not fun trying to regain control without a full reboot.  I've changed the default to "1" instead. ) 
# If you have enough RAM, and few enough files being cached, you can specify "-p 0" on the command line
# to set the vfs_cache_pressure to 0.  Otherwise, this default value of 1 should prevent memory starvation 
# and the OOM (out-of-memory) state killing on your processes to free up some RAM.
# 1 did not do it with my 500Meg of RAM... trying cache_pressure of 10, use -p 1 if you still want the old value
cache_pressure=10  

while getopts ":p:m:M:Fvc:d:e:qi:szl:BwuVa:S" opt; do
  case $opt in
  m ) min_seconds=$OPTARG ;;
  M ) max_seconds=$OPTARG ;;
  F ) background=no ;;
  v ) verbose=yes ;;
  V ) echo $program_name version: $version
      exit 0 ;;
  u)  user_share_dir="/mnt/user" ;;
  c ) command="$OPTARG" ;;
  a ) args="$OPTARG" ;;
  d ) maxdepth=$OPTARG 
      command="find" ;;
  i ) include_array[$include_array_count]="$OPTARG"
      include_array_count=$(($include_array_count+1)) ;;
  e ) exclude_array[$exclude_array_count]="$OPTARG"
      exclude_array_count=$(($exclude_array_count+1)) ;;
  h ) usage >&2 ; exit ;;
  p ) cache_pressure="$OPTARG" ;;
  q ) quit_flag="yes" ;;
  w ) wait_flag="yes" ;;
  s ) short_log="yes" ;;
  B ) force_disk_busy_flag="no" ;;
  S ) suspend_during_mover="no" ;;
  z ) concise_log="yes" ;;
  l ) if [ "$arg_count" -ne 2 ]
      then
        echo "-l option may not be used in combination with others."
        echo "Usage:" >&2
        echo "cache_dirs -l on" >&2
        echo "or" >&2
        echo "cache_dirs -l off" >&2
        exit 2
      fi
      case "$OPTARG" in
      on)
        echo >$run_log
        echo "Logging enabled to $run_log"
        exit 0
      ;;
      off)
        rm "$run_log"
        echo "Logging to $run_log stopped"
        exit 0
      ;;
      *)
        echo "Invalid argument to -l option"
        echo "Usage:" >&2
        echo "cache_dirs -l on" >&2
        echo "or" >&2
        echo "cache_dirs -l off" >&2
        exit 2
      ;;
      esac
      ;;
  \?) usage >&2 ; exit ;;
  esac
done

#Try to play nice
ulimit -v 5000

lockfile="/var/lock/cache_dirs.LCK"
if [ -f "${lockfile}" ]; then

  # The file exists so read the PID
  # to see if it is still running
  lock_pid=`head -n 1 "${lockfile}"`

  pid_running=`ps -p "${lock_pid}" | grep ${lock_pid}`

  if [ -z "${pid_running}" ]; then
    if [ "$quit_flag" = "no" ]
    then
      # The process is not running
      # Echo current PID into lock file
      echo $$ > "${lockfile}"
    else
      echo "$program_name ${lock_pid} is not currently running "
      rm "${lockfile}"
      exit 0
    fi
  else
    if [ "$quit_flag" = "yes" ]
    then
      echo killing $program_name process "$lock_pid"
      echo killing $program_name process "$lock_pid" | logger -t$program_name 
      kill "$lock_pid"
      rm "${lockfile}"
      exit 0
    else
      echo "$program_name is already running [${lock_pid}]"
      exit 2
    fi
  fi
else
  if [ "$quit_flag" = "yes" ]
  then
    echo "$program_name not currently running "
    exit 0
  else
    echo $$ > "${lockfile}"
  fi
fi

# validate the cache pressure
cc="$(echo $cache_pressure | sed 's/[0-9]//g')"
if [ ! -z "$cc" ]
then
  echo "error: cache_pressure must be numeric." >&2
  usage >&2
  exit 2
fi

# validate the min number of seconds
cc="$(echo $min_seconds | sed 's/[0-9]//g')"
if [ ! -z "$cc" ]
then
  echo "error: min number of seconds must be numeric (whole number, not negative)." >&2
  usage >&2
  exit 2
fi

# validate the max number of seconds
cc="$(echo $max_seconds | sed 's/[0-9]//g')"
if [ ! -z "$cc" ]
then
  echo "error: max number of seconds must be numeric." >&2
  usage >&2
  exit 2
fi
if [ $max_seconds -lt $min_seconds ]
then
  echo "error: max number of seconds must be greater than or equal min number of seconds." >&2
  usage >&2
  exit 2
fi

# validate the maxdepth
cc="$(echo $maxdepth | sed 's/[0-9]//g')"
if [ ! -z "$cc" ]
then
  echo "error: directory scan maxdepth must be numeric." >&2
  usage >&2
  exit 2
fi

shift $(($OPTIND - 1))

# start out in the middle of the range allowed.
num_seconds=$((( $max_seconds + $min_seconds ) / 2 ))

sysctl vm.vfs_cache_pressure=$cache_pressure >/dev/null 2>&1

build_dir_list() {
  # build a list of directories to cache.  
  #   If no "-i" options are given, this will be all the top level directories in /mnt/disk* and /mnt/cache
  #   If "-i" entries are given, they will be the only top level dirs cached.
  #   If "-e" (exclude) directories are given, they are then deleted from the list by the comm -23 coommand.
  if [ $include_array_count -gt 0 ]
  then
    top_dirs=`(
     # Include designated directories 
     a=0
     while test $a -lt $include_array_count
     do
       included_excl=$(find /mnt/disk* /mnt/cache -type d -maxdepth 1 -mindepth 1 -name "${include_array[$a]}" -exec basename {} \; 2>/dev/null)
       echo "$included_excl" | sort -u
       a=$(($a+1))
     done
    )| sort -u`
  else
    top_dirs=`find /mnt/disk* /mnt/cache -type d -maxdepth 1 -mindepth 1  -exec basename {} \; 2>/dev/null|sort -u`
  fi
  exclude_dirs=`(
     # Exclude designated directories from being processed
     a=0
     while test $a -lt $exclude_array_count
     do
       expanded_excl=$(find /mnt/disk* /mnt/cache -type d -maxdepth 1 -mindepth 1 -name "${exclude_array[$a]}" -exec basename {} \; 2>/dev/null)
       echo "$expanded_excl" | sort -u
       a=$(($a+1))
     done
    )| sort -u`
   scan_dirs=`comm -23 <(echo "$top_dirs") <(echo "$exclude_dirs")`
   echo "$scan_dirs"
}

# build a command string for "at" to start later if not on-line and -w option used
at_command=`(
echo -n $program_dir/$program_name -w -m $min_seconds -M $max_seconds -d $maxdepth -p $cache_pressure 
[ $command != "find" ] && echo -n " -c \"$command\""
 a=0
 while test $a -lt $exclude_array_count
 do
   echo -n " -e \"${exclude_array[$a]}"\"
   a=$(($a+1))
 done
 a=0
 while test $a -lt $include_array_count
 do
   echo -n " -i \"${include_array[$a]}"\"
   a=$(($a+1))
 done
 [ $force_disk_busy_flag = "no" ] && echo -n " -B"
 [ $suspend_during_mover = "no" ] && echo -n " -S"
 [ $concise_log = "yes" ] && echo -n " -z"
 [ $short_log = "yes" ] && echo -n " -s"
 [ "$user_share_dir" != "" ] && echo -n " -u"
 [ "$args" != "" ] && echo -n " -a \"$args\""
 echo
)`

num_dirs=`find /mnt/disk[1-9]* /mnt/cache -type d -maxdepth 0 -print 2>/dev/null|wc -l`
if [ $num_dirs -eq 0 ]
then
  # Wait for the array to come online
  if [ "$wait_flag" = "yes"  -a "$background" = "yes" ]
  then
    echo $at_command " 1>/dev/null 2>&1" | at now + 1 minute
    [ -f /dev/tty ] && echo "The unRAID array is not online.  Directory scan will occur when array comes online." >/dev/tty
    exit 0
  else
    if [ "$wait_flag" = "yes" ]
    then
      echo "-F and -w may not be used at the same time. Directory scan by $program_name not started." >&2
    else
      echo "The unRAID array is not online.  Directory scan by $program_name not started." >&2
    fi
    exit 2
  fi
fi

dir_list=`build_dir_list`

if [ $short_log = "no" ]
then
  log_list="$dir_list"
else
  log_list=$(echo "$dir_list" | wc -l)
  log_list=$(echo $log_list " directories cached")
fi

if [ "$concise_log" = "no" ]
then
echo "==============================================
command-args=$commandargs
vfs_cache_pressure=$cache_pressure
max_seconds=$max_seconds, min_seconds=$min_seconds
max_depth=$maxdepth
command=$command $args
version=$version
---------- caching directories ---------------
$log_list
----------------------------------------------" | logger -t$program_name 
else
echo "command args=$commandargs, version=$version, vfs_cache_pressure=$cache_pressure,
max_seconds=$max_seconds, min_seconds=$min_seconds, max_depth=$maxdepth, command=$command $args
$log_list" | paste -s -d "," - | logger -t$program_name
fi

# Create a child process with a "current working directory" on each of the disks
# These will prevent their un-mounting, and they will prevent an unexpected surprise
# of "unformatted" disks showing in the management web-page when some disks are un-mounted
# and other disks are not able to be un-mounted, because they were "busy"  
# This guarantees that all the disks will be "busy" until the lockfile is removed
# or these child processes are terminated. No disk may then be un-mounted until these
# processes terminate.  They will all self-terminate if the lockfile is removed.
if [ "$force_disk_busy_flag" = "yes" ]
then
a=0
for i in /mnt/disk*  /mnt/cache
do
  [ ! -d $i ] && continue
  ( trap "kill -0 `cat $lockfile` && kill `cat $lockfile`; rm $lockfile" 15; cd $i; while test -f "$lockfile" && kill -0 `cat $lockfile` 2>/dev/null; do sleep 2; done ) &
  bg_process[$a]=$!
  a=$(($a+1))
done
fi

a=0
while test $a -lt $exclude_array_count
do
  list=`eval ls /mnt/disk*/"${exclude_array[$a]}" /mnt/cache/"${exclude_array[$a]}" 2>/dev/null`
  if [ "$list" = "" ]
  then
     echo "ERROR: excluded directory \"${exclude_array[$a]}\" does not exist." >&2
     echo "ERROR: excluded directory \"${exclude_array[$a]}\" does not exist." | logger -t$program_name
  fi
  a=$(($a+1))
done
a=0
while test $a -lt $include_array_count
do
  list=`eval ls /mnt/disk*/"${include_array[$a]}" /mnt/cache/"${include_array[$a]}" 2>/dev/null`
  if [ "$list" = "" ]
  then
     echo "ERROR: included directory \"${include_array[$a]}\" does not exist." >&2
     echo "ERROR: included directory \"${include_array[$a]}\" does not exist." | logger -t$program_name
  fi
  a=$(($a+1))
done

depth=""
[ "$maxdepth" -ne 9999 ] && depth="-maxdepth $maxdepth"

while [ -f "$lockfile" ]
do

  if [ "$suspend_during_mover"="yes" ]; then
    if [ -f /var/run/mover.pid ]; then
      if ps h `cat /var/run/mover.pid` | grep mover >/dev/null 2>&1 ; then
         sleep 10
         continue
      fi
    fi
  fi

  num_dirs=`find /mnt/disk[1-9]* /mnt/cache -type d -maxdepth 0 -print 2>/dev/null|wc -l`
  if [ "$num_dirs" -eq 0 ]
  then
    # array is not started, sleep and look again in 10 seconds.
    sleep 10
    continue
  fi

  start_time=`date +%s%N`

  # always cache root dirs on each of the disks
  for i in /mnt/disk* /mnt/cache $user_share_dir
  do
    find $i -maxdepth 1 -noleaf >/dev/null 2>/dev/null 
  done
  #find /mnt/user/Movies -type f \( -name *.jpg -o -name *.xml \) -exec cat "{}" >/dev/null \;

  echo "$dir_list" | while read share_dir
  do
     for i in /mnt/disk* /mnt/cache $user_share_dir
     do
       # If the directory does not exist on this disk, don't do recursive "directory scan"
       [ ! -d "$i"/"$share_dir" ] && continue

       # Perform a recursive "find" on /mnt/disk??/share
       $command "$i"/"$share_dir" $args $depth >/dev/null 2>&1
       [ $background = "no" -a $verbose = "yes" ] && echo "Executing $command $i/$share_dir $args $depth"
     done
  done

  end_time=`date +%s%N`

  # track how long the recursive "directory scan" is taking.  If it starts to take longer it must be
  # because it has to read more from the physical disk.  If so, adjust the timing to
  # perform the directory scan more frequently.
  elapsed_time=$(($end_time-$start_time))

  alen=${#avg[@]}
  # Move all the counts up one position in the array.
  for (( i = $(($alen)) ; i > 0 ; i-- ))
  do
    [ $i -lt $window_array_length ] && avg[$(($i+1))]=${avg[$i]}
  done
  
  # The newest will always be stored at index 1
  avg[1]=$elapsed_time

  # get the weighted average of the last $window_array_length loop passes
  # more recent values count far more than older values.
  tot_time=0
  alen=${#avg[@]}

  tot_count=0
  for (( i = 1; i <= $alen; i++ ))
  do
    weight=$(( $alen - $i + 1 ))
    weight=$(( $weight * 3 ))
    tot_count=$(( $tot_count + $weight))
    tot_time=$(( $tot_time + $(( ${avg[$i]} * $weight ))))
  done
  avg_elapsed_time=$(($tot_time/$tot_count))

  [ $avg_elapsed_time -eq 0 ] && avg_elapsed_time=$elapsed_time

  [ $avg_elapsed_time -lt $(($elapsed_time+100000)) -a $num_seconds -gt $min_seconds  ] && num_seconds=$(($num_seconds-1))
  [ $avg_elapsed_time -gt $(($elapsed_time-100000)) -a $num_seconds -lt $max_seconds ] && num_seconds=$(($num_seconds+1))
  if [ "$background" = "no" -o "$run_log" != "" ]
  then
   a=`awk "BEGIN{ printf \\"%f seconds, weighted avg=%f\n\\", ($elapsed_time/1000000000), ($avg_elapsed_time/1000000000) ; }"`
  fi
  [ $background = "no" ] && echo "Executed $command in $a seconds, now sleeping $num_seconds seconds"
  [ "$run_log" != "" -a -f "$run_log" ] && echo "Executed $command in $a seconds, now sleeping $num_seconds seconds" >>$run_log

  sleep $num_seconds
  if [ "$force_disk_busy_flag" = "yes" ]
  then
    # if the user attempted to stop the array, terminate this process so it can be stopped next time they try.
    stop_attempt=`tail -200 /var/log/syslog | egrep "devices still in use|mdcmd.*stop|Retry unmounting disk share"`
    if [ "$stop_attempt" != "" ] 
    then
       for bg_pid in ${bg_process[@]}
       do
         kill $bg_pid >/dev/null 2>&1
       done
       echo "Suspending $program_name for $suspend_secs seconds to allow for clean shutdown of array" | logger -t$program_name
       echo "While suspended, pressing \"Stop\" on the unRAID management web-interface will shutdown the array" | logger -t$program_name
       sleep $suspend_secs
       echo "  Resuming $program_name" | logger -t$program_name
       a=0
       for i in /mnt/disk*  /mnt/cache
       do
         [ ! -d $i ] && continue
         ( cd $i; while test -f "$lockfile"; do sleep 2; done ) &
         bg_process[$a]=$!
         a=$(($a+1))
       done
    fi
  fi
  # If the array is now stopped, terminate cache_dirs and re-invoke later via "at"
  num_dirs=`find /mnt/disk[1-9]* -type d -maxdepth 0 -print 2>/dev/null|wc -l`
  if [ "$num_dirs" -eq 0 ]
  then
    if [ "$background" = "yes" ]
    then
      rm -f $lockfile
      echo scheduling via at $at_command  | logger -t$program_name
      echo $at_command " 1>/dev/null 2>&1" | at now + 1 minute
    fi
  fi

done &


# while loop was put into background, now disown it 
# so it will continue to run when you log off
# to get it to stop, type: rm /var/lock/cache_dirs.LCK
background_pid=$!
echo $background_pid > "${lockfile}"
if [ $background = "no" ] 
then
  # only way to get here is to remove the lock file or kill the background process shell with the while loop
  trap "rm -f $lockfile; kill $background_pid 2>/dev/null; exit" INT TERM EXIT
  wait
else
  echo "$program_name process ID $background_pid started, To terminate it, type: $program_name -q" >&2
  echo "$program_name process ID $background_pid started, To terminate it, type: $program_name -q" | logger -t$program_name 
  disown %%
fi
